{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8e3a41d",
   "metadata": {},
   "source": [
    "## SFT训练Qwen小模型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ac90772",
   "metadata": {},
   "source": [
    "### wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97cf79ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install wandb\n",
    "import wandb\n",
    "wandb.login(key=\"your_wandb_api_key_here\")  # 替换为你的wandb API密钥\n",
    "project_name = \"SFT-Qwen2.5-3B\" # todo: wandb项目命名\n",
    "# project_name = \"SFT-Qwen2.5-0.5B-final\"\n",
    "wandb.init(project = project_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c91e4d9b",
   "metadata": {},
   "source": [
    "### 库 和 提示词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6dda578",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "from trl import SFTConfig, SFTTrainer\n",
    "import json\n",
    "from modelscope import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "from peft import LoraConfig\n",
    "\n",
    "print('cuda support:',torch.cuda.is_available())\n",
    "\n",
    "SYSTEM_PROMPT='''\n",
    "# Role\n",
    "I am an elementary school math tutor. Currently, I will give a clear and easy-to-understand explanation for a specific elementary school math word problem.\n",
    "Note that the response should be in the form of spoken textual expression, and avoid including the formats such as pictures, hyperlinks, etc.\n",
    "\n",
    "# Precautions\n",
    "1. Fully consider the cognitive level and knowledge reserve of primary school students.\n",
    "2. If the problem is complex, break it down into simple steps. Avoid using professional terms and explain it in plain language.\n",
    "3. Make more use of real-life examples and intuitive teaching aids to assist in teaching.\n",
    "\n",
    "# Teaching Style\n",
    "Adopt a step-by-step teaching method, combined with interactive Q&A sessions and classroom exercises; encourage students through positive feedback to strengthen their understanding of mathematical concepts.\n",
    "\n",
    "# Answer Format\n",
    "<reasoning>\n",
    "Break down, analyze, and reflect on the problem step by step to sort out the thinking process of the solution.\n",
    "</reasoning>\n",
    "<answer>\n",
    "Start explaining the problem from the first-person perspective of a math tutor.\n",
    "</answer>\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df0fb60",
   "metadata": {},
   "source": [
    "### 加载模型、分词器、蒸馏的数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc138cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载蒸馏得到的数据集\n",
    "def load_distill_dataset():\n",
    "    ds={'messages':[]}\n",
    "    with open('r1_distill.txt','r') as f:\n",
    "        lines=f.readlines()\n",
    "        for line in lines:\n",
    "            line=json.loads(line)\n",
    "            sample=[\n",
    "                    {'role':'system','content':SYSTEM_PROMPT}, \n",
    "                    {'role':'user','content': line['question']}, \n",
    "                    {'role':'assistant','content': f\"<reasoning>\\n{line['reasoning']}\\n</reasoning>\\n<answer>\\n{line['answer']}\\n</answer>\"},\n",
    "            ]\n",
    "            ds['messages'].append(sample)\n",
    "    return Dataset.from_dict(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db792030",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name='Qwen2.5-3B-Instruct' # todo: 选取模型\n",
    "model_dir='models/' + model_name\n",
    "model=AutoModelForCausalLM.from_pretrained(model_dir,torch_dtype=\"auto\",device_map=\"auto\")\n",
    "tokenizer=AutoTokenizer.from_pretrained(model_dir)\n",
    "dataset=load_distill_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c6aecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c8598f",
   "metadata": {},
   "source": [
    "### 训练"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3365c845",
   "metadata": {},
   "source": [
    "#### SFT 和 LoRA 配置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ac88c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义SFT（Supervised Fine-Tuning）配置，设置训练的各种参数\n",
    "sft_config=SFTConfig(\n",
    "    per_device_train_batch_size=1,\n",
    "    gradient_accumulation_steps=4,\n",
    "    lr_scheduler_type='linear',\n",
    "    warmup_ratio=0.1,\n",
    "    learning_rate=5e-6,\n",
    "    max_seq_length=500,\n",
    "    logging_steps=1,\n",
    "    save_steps=0.3,\n",
    "    num_train_epochs=2,\n",
    "    report_to='wandb',\n",
    "    fp16=True,\n",
    "    max_grad_norm=0.1,\n",
    "    output_dir='models/' + model_name + '-SFT', \n",
    ")\n",
    "\n",
    "# 定义LoRA（Low-Rank Adaptation）配置，用于对模型进行低秩适应\n",
    "lora_config=LoraConfig(\n",
    "    r=32,\n",
    "    lora_alpha=64,\n",
    "    target_modules=['q_proj','k_proj','v_proj','o_proj','gate_proj','up_proj','down_proj'],  # 要应用LoRA的目标模块\n",
    "    lora_dropout=0.05,\n",
    "    task_type='CAUSAL_LM',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "452444c1",
   "metadata": {},
   "source": [
    "#### 创建SFT训练器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "503e40ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建SFT训练器对象，传入模型、分词器、训练数据集、SFT配置和LoRA配置\n",
    "trainer=SFTTrainer(\n",
    "    model=model,\n",
    "    processing_class=tokenizer,\n",
    "    train_dataset=dataset,\n",
    "    args=sft_config,\n",
    "    peft_config=lora_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d850ee6f",
   "metadata": {},
   "source": [
    "#### 开始训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ee05ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()\n",
    "\n",
    "output_dir='models/' + model_name + '-SFT'\n",
    "trainer.save_model(output_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myLM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
